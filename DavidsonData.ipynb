{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import csv\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in original davidson data\n",
    "davidson_og=pd.read_csv(\"davidson_labeled_data_copy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Cleanup\n",
    "\n",
    "Apply custom clean_tweets function to clean tweets of @tags and emoticon ASCII codes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#present a good example for before and after cleaning\n",
    "print(davidson_og['tweet'][1556])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet): \n",
    "    tweet = re.sub('@[^ ]+ ', '', tweet) #remove user @ tags\n",
    "    tweet = re.sub('&[^;]+;', '', tweet) #remove ascii codes for emojis\n",
    "    tweet = re.sub('http://[^ ]+','', tweet) #remove http:// hyperlinks\n",
    "    tweet = re.sub('https://[^ ]+','', tweet) #remove https:// hyperlinks\n",
    "    tweet = tweet.replace('=', '', 1) #remove '=' at the beginning of some messages\n",
    "    tweet = tweet.replace('\\\\n', ' ') #trim out \\\\n\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply clean_tweets custom function\n",
    "davidson_clean = davidson_og.copy()\n",
    "davidson_clean['tweet'] = davidson_clean['tweet'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#present cleaned tweet example from above\n",
    "print(davidson_clean['tweet'][1556])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_clean = davidson_clean.loc[davidson_clean['tweet'] != ''] #remove any blank tweets\n",
    "davidson_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_clean.to_csv(\"davidson_labeled_data_replaced.csv\", index=False) #create cleaned csv file\n",
    "davidson_clean.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambiguous Split\n",
    "\n",
    "Class 0 = Hate Speech, Class 1 = Offensive Language, Class 2 = Neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_replaced = pd.read_csv('davidson_labeled_data_replaced.csv') #read cleaned tweets\n",
    "keep_col = ['count', 'hate_speech', 'offensive_language', 'neither', 'class', 'tweet'] #created for abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_hate = davidson_replaced.loc[(davidson_replaced['offensive_language'] == 0) & (davidson_replaced['neither'] == 0) \\\n",
    "                                    & (davidson_replaced['class'] == 0)] #select tweets that were deemed universally hateful\n",
    "davidson_hate_tweets = davidson_hate[keep_col]\n",
    "davidson_hate_tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_hate_tweets.to_csv('davidson_hate_only.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_hate_mix = davidson_replaced.loc[(davidson_replaced['count'] != davidson_replaced['hate_speech']) \\\n",
    "                                             & (davidson_replaced['class'] == 0)] #select tweets that had a majority but not unanimous hate vote\n",
    "davidson_hate_mix_tweets = davidson_hate_mix[keep_col]\n",
    "davidson_hate_mix_tweets.to_csv(\"davidson_hate_mix.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_clean = davidson_replaced.loc[(davidson_replaced['offensive_language'] == 0) & (davidson_replaced['hate_speech'] == 0) \\\n",
    "                                    & (davidson_replaced['class'] == 2)] #select tweets that were deemed universally clean content\n",
    "davidson_clean_tweets = davidson_clean[keep_col]\n",
    "davidson_clean_tweets.to_csv('davidson_clean_only.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
