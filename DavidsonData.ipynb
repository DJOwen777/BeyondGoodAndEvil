{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import csv\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in original davidson data\n",
    "davidsonOG=pd.read_csv(\"davidson_labeled_data_copy.csv\")\n",
    "davidsonOG.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Cleanup\n",
    "\n",
    "Apply custom clean_tweets function to clean tweets of @tags and emoticon ASCII codes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#present a good example for before and after cleaning\n",
    "message = davidsonOG['tweet'][1556]\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet): \n",
    "    tweet = re.sub('@[^ ]+ ', '', tweet) #remove user @ tags\n",
    "    tweet = re.sub('&[^;]+;', '', tweet) #remove ascii codes for emojis\n",
    "    tweet = tweet.replace('=', '', 1) #remove '=' at the beginning of some messages\n",
    "    tweet = tweet.replace('\\\\n', ' ') #trim out \\\\n\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply clean_tweets custom function\n",
    "davidsonOG['tweet'] = davidsonOG['tweet'].apply(clean_tweets)\n",
    "\n",
    "#present cleaned tweet example from above\n",
    "print(davidsonOG['tweet'][1556])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidsonOG = davidsonOG.loc[davidsonOG['tweet'] != ''] #remove any blank tweets\n",
    "davidsonOG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidsonOG.to_csv(\"davidson_labeled_data_replaced.csv\", index=False) #create cleaned csv file\n",
    "davidsonOG.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambiguous Split\n",
    "\n",
    "Class 0 = Hate Speech, Class 1 = Offensive Language, Class 2 = Neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidsonReplaced = pd.read_csv('davidson_labeled_data_replaced.csv') #read cleaned tweets\n",
    "keepCol = ['count', 'hate_speech', 'offensive_language', 'neither', 'class', 'tweet'] #created for abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidsonHate = davidsonReplaced.loc[(davidsonReplaced['offensive_language'] == 0) & (davidsonReplaced['neither'] == 0) \\\n",
    "                                    & (davidsonReplaced['class'] == 0)] #select tweets that were deemed universally hateful\n",
    "davidsonHateTweets = davidsonHate[keepCol]\n",
    "davidsonHateTweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidsonHateTweets.to_csv('DavidsonHateOnly.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidsonHateMix = davidsonReplaced.loc[(davidsonReplaced['count'] != davidsonReplaced['hate_speech']) \\\n",
    "                                             & (davidsonReplaced['class'] == 0)] #select tweets that had a majority but not unanimous hate vote\n",
    "davidsonHateMixTweets = davidsonHateMix[keepCol]\n",
    "davidsonHateMixTweets.to_csv(\"DavidsonHateMix.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidsonClean = davidsonReplaced.loc[(davidsonReplaced['offensive_language'] == 0) & (davidsonReplaced['hate_speech'] == 0) \\\n",
    "                                    & (davidsonReplaced['class'] == 2)] #select tweets that were deemed universally clean content\n",
    "davidsonCleanTweets = davidsonClean[keepCol]\n",
    "davidsonCleanTweets.to_csv('DavidsonCleanOnly.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
